# -*- coding: utf-8 -*-
"""Untitled0.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/108ahPt9kBrKDWJipwrQDTpZPgbm5wHsZ
"""

# =========================
# COMPLETE TELCO CHURN PROJECT
# =========================
# Run this in Google Colab / Kaggle (adjust dataset path if needed)
# Colab path example: "/content/Customer-Churn.xlsx"
# Kaggle path example: "../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv"
# =========================

# 0) Imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings("ignore")

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from sklearn.preprocessing import StandardScaler
import xgboost as xgb
import shap
import joblib
import os
import math
from scipy import stats
np.random.seed(42)

# -------------------------
# 1) Load dataset (try Excel then CSV)
# -------------------------
# Edit this path if your file is elsewhere
possible_paths = [
    "/content/Customer-Churn.xlsx",
    "/content/WA_Fn-UseC_-Telco-Customer-Churn.csv",
    "../input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv"
]

loaded = False
for p in possible_paths:
    if os.path.exists(p):
        if p.endswith(".xlsx"):
            df = pd.read_excel(p)
        else:
            df = pd.read_csv(p)
        loaded = True
        print("Loaded:", p)
        break

if not loaded:
    raise FileNotFoundError("Dataset not found. Put your file at /content/Customer-Churn.xlsx or adjust path.")

# Quick peek
print("\nRows,Cols:", df.shape)
display(df.head())

# -------------------------
# 2) Clean column names & check important columns
# -------------------------
df.columns = df.columns.astype(str)
df.columns = df.columns.str.strip().str.replace(" ", "").str.replace("\t","")
print("\nColumns after cleaning:", list(df.columns))

# If there is a customer id-like column, drop it safely
candidate_id_cols = [c for c in df.columns if c.lower().startswith("customer")]
for c in candidate_id_cols:
    if c.lower() == "customerid" or c.lower().startswith("customerid"):
        print("Dropping id column:", c)
        df = df.drop(columns=[c])
        break

# -------------------------
# 3) Fix TotalCharges (common telco issue)
# -------------------------
if "TotalCharges" in df.columns and df["TotalCharges"].dtype == object:
    # remove spaces and coerce to numeric
    df["TotalCharges"] = df["TotalCharges"].str.strip().replace("", np.nan)
    df["TotalCharges"] = pd.to_numeric(df["TotalCharges"], errors="coerce")
    # fill missing with median (safe)
    df["TotalCharges"] = df["TotalCharges"].fillna(df["TotalCharges"].median())
    print("Fixed TotalCharges -> numeric")

# -------------------------
# 4) Basic cleaning: fill missing, unify dtypes
# -------------------------
# Fill object NaNs
for c in df.columns:
    if df[c].dtype == object:
        df[c] = df[c].fillna("Unknown")

# For numeric columns fill with median (if any)
for c in df.select_dtypes(include=[np.number]).columns:
    df[c] = df[c].fillna(df[c].median())

# Ensure target exists and is 0/1
if "Churn" not in df.columns:
    raise KeyError("Dataset must contain 'Churn' column")
if df["Churn"].dtype == object:
    df["Churn"] = df["Churn"].map({"Yes":1, "No":0}).fillna(df["Churn"])
df["Churn"] = df["Churn"].astype(int)

print("\nValue counts for churn:")
print(df["Churn"].value_counts())

# -------------------------
# 5) FEATURE ENGINEERING (2 non-trivial features)
# -------------------------
# Feature 1: avg_monthly_spend = TotalCharges / (tenure + 1)  (captures long-time spend behavior)
df["avg_monthly_spend"] = df["TotalCharges"] / (df["tenure"] + 1)

# Feature 2 (non-trivial): service_count = number of 'Yes' across service columns
service_cols = [
    c for c in df.columns
    if c in ["PhoneService","MultipleLines","InternetService","OnlineSecurity","OnlineBackup",
             "DeviceProtection","TechSupport","StreamingTV","StreamingMovies"]
]
# If InternetService is categorical (e.g., DSL, Fiber, No) we treat 'No' as no service
if "InternetService" in df.columns:
    # count services: treat PhoneService, MultipleLines, OnlineSecurity... as 'Yes'/'No' flags
    def is_service_yes(val):
        if pd.isna(val): return 0
        if isinstance(val, str):
            v = val.strip().lower()
            return 0 if v in ["no","no internet service","unknown"] else 1
        return 1 if val else 0

    df["service_count"] = 0
    for c in service_cols:
        df["service_count"] += df[c].apply(is_service_yes)

# Extra engineered: value_score = avg_monthly_spend / (service_count + 0.5)
df["value_score"] = df["avg_monthly_spend"] / (df["service_count"] + 0.5)

# Clip extreme values to reduce effect of outliers
for col in ["avg_monthly_spend","value_score"]:
    df[col] = np.clip(df[col], a_min=0, a_max=np.percentile(df[col].dropna(), 99.5))

# Show new features
print("\nNew features added: avg_monthly_spend, service_count, value_score")
display(df[["tenure","MonthlyCharges","TotalCharges","avg_monthly_spend","service_count","value_score"]].head())

# -------------------------
# 6) Encoding: convert categorical variables
# -------------------------
# Identify categorical cols (object) excluding target
cat_cols = df.select_dtypes(include=["object"]).columns.tolist()
print("\nCategorical columns:", cat_cols)

# We'll one-hot encode categorical variables (drop_first=True)
df_enc = pd.get_dummies(df, columns=cat_cols, drop_first=True)
print("\nAfter encoding shape:", df_enc.shape)

# -------------------------
# 7) Prepare X and y, train-test split
# -------------------------
y = df_enc["Churn"].astype(int)
X = df_enc.drop(columns=["Churn"])

# Scale numeric features for SHAP interpretability (optional)
num_cols = X.select_dtypes(include=[np.number]).columns.tolist()
scaler = StandardScaler()
X[num_cols] = scaler.fit_transform(X[num_cols])

# train-test split with stratify
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)
print("\nTrain/test shapes:", X_train.shape, X_test.shape)

# -------------------------
# 8) Handle class imbalance for XGBoost via scale_pos_weight
# -------------------------
pos = y_train.sum()
neg = y_train.shape[0] - pos
scale_pos_weight = neg / (pos + 1e-6)
print("scale_pos_weight for XGBoost:", round(scale_pos_weight,2))

# -------------------------
# 9) Train XGBoost with RandomizedSearchCV (tuning)
# -------------------------
xgb_clf = xgb.XGBClassifier(
    objective="binary:logistic",
    use_label_encoder=False,
    eval_metric="logloss",
    random_state=42,
    n_jobs=-1
)

param_dist = {
    "n_estimators": [100, 200, 400, 600],
    "max_depth": [3, 4, 6, 8],
    "learning_rate": [0.01, 0.03, 0.05, 0.1],
    "subsample": [0.6, 0.8, 1.0],
    "colsample_bytree": [0.6, 0.8, 1.0],
    "gamma": [0, 1, 5]
}

search = RandomizedSearchCV(
    estimator=xgb_clf,
    param_distributions=param_dist,
    n_iter=20,
    scoring="roc_auc",
    cv=3,
    verbose=1,
    random_state=42,
    n_jobs=-1
)

# set scale_pos_weight before search using base estimator params
xgb_clf.set_params(scale_pos_weight=scale_pos_weight)
search.fit(X_train, y_train)
best_model = search.best_estimator_
print("\nBest params:", search.best_params_)

# -------------------------
# 10) Evaluate on test set
# -------------------------
y_proba = best_model.predict_proba(X_test)[:,1]
y_pred = (y_proba >= 0.5).astype(int)

auc = roc_auc_score(y_test, y_proba)
prec = precision_score(y_test, y_pred, zero_division=0)
rec = recall_score(y_test, y_pred, zero_division=0)
f1 = f1_score(y_test, y_pred, zero_division=0)
cm = confusion_matrix(y_test, y_pred)

print(f"\nTest AUC: {auc:.4f}")
print(f"Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}")
print("Confusion Matrix:\n", cm)
print("\nClassification Report:\n", classification_report(y_test, y_pred, zero_division=0))

# -------------------------
# 11) SHAP analysis
# -------------------------
# use TreeExplainer (fast for tree models)
explainer = shap.TreeExplainer(best_model)
# compute shap values on a sample to save time if X_test large
sample_for_shap = X_test.sample(n=min(2000, X_test.shape[0]), random_state=42)
shap_values = explainer.shap_values(sample_for_shap)

# Global: summary plot
plt.figure(figsize=(10,6))
shap.summary_plot(shap_values, sample_for_shap, show=False)
plt.title("SHAP summary: feature importance and effect")
plt.tight_layout()
plt.show()

# SHAP bar plot (mean absolute)
plt.figure(figsize=(8,6))
shap.summary_plot(shap_values, sample_for_shap, plot_type="bar", show=False)
plt.title("SHAP feature importance (mean |SHAP|)")
plt.tight_layout()
plt.show()

# Dependence plot for top numeric feature
# find top feature name by mean(|shap|)
shap_abs_mean = np.abs(shap_values).mean(axis=0)
top_idx = np.argsort(shap_abs_mean)[-1]
top_feature = sample_for_shap.columns[top_idx]
print("\nTop SHAP feature:", top_feature)

plt.figure(figsize=(8,5))
shap.dependence_plot(top_feature, shap_values, sample_for_shap, show=False)
plt.title(f"SHAP dependence plot for {top_feature}")
plt.tight_layout()
plt.show()

# -------------------------
# 12) Local explanations: 3 customers (high, low, mid)
# -------------------------
# compute probabilities for full X_test (not only sample)
y_proba_full = best_model.predict_proba(X_test)[:,1]
high_idx = np.argmax(y_proba_full)
low_idx = np.argmin(y_proba_full)
mid_idx = np.argmin(np.abs(y_proba_full - 0.5))

# create a small function to show local force plot (matplotlib)
def show_force_for_index(idx, X_df, model, explainer):
    obs = X_df.iloc[[idx]]
    sv = explainer.shap_values(obs)
    print(f"\nIndex {idx} predicted_proba={model.predict_proba(obs)[0,1]:.3f}")
    shap.plots.force(sv, matplotlib=True)
    plt.show()

# Note: indices are positions in X_test; map to sample indices for SHAP if needed
# We will display using the sample we computed earlier if idx in its index; else use explainer on single row
print("\n-- High churn example --")
show_force_for_index(high_idx, X_test.reset_index(drop=True), best_model, explainer)

print("\n-- Low churn example --")
show_force_for_index(low_idx, X_test.reset_index(drop=True), best_model, explainer)

print("\n-- Mid churn example --")
show_force_for_index(mid_idx, X_test.reset_index(drop=True), best_model, explainer)

# -------------------------
# 13) Feature importance table & save
# -------------------------
feat_imp_df = pd.DataFrame({
    "feature": X.columns,
    "importance": best_model.feature_importances_
}).sort_values(by="importance", ascending=False).reset_index(drop=True)

print("\nTop 15 features by model importance:")
display(feat_imp_df.head(15))

# -------------------------
# 14) Output: feature descriptions and executive summary text (copy-paste)
# -------------------------
feature_descriptions = {
    "avg_monthly_spend": "TotalCharges divided by (tenure+1). Captures how much a customer spends per month averaged over their tenure.",
    "service_count": "Count of active services (Phone, OnlineSecurity, Streaming, etc.). More services usually means stickier customers.",
    "value_score": "avg_monthly_spend divided by (service_count+0.5). Higher values may indicate expensive customers with few services (higher risk)."
}

print("\nFEATURE DESCRIPTIONS (two non-trivial features):")
for k,v in feature_descriptions.items():
    print(f"- {k}: {v}")

# Executive summary paragraph (ready to paste)
exec_summary = f"""
Executive Summary:
I trained an XGBoost model to predict customer churn using the Telco dataset. I engineered two non-trivial features:
1) avg_monthly_spend: total charges divided by tenure (captures monthly spend behavior),
2) service_count: number of active services (captures product footprint and stickiness),
and a derived value_score combining spend and services.

Model performance on the hold-out test set:
- AUC: {auc:.4f}
- Precision: {prec:.4f}
- Recall: {rec:.4f}
- F1: {f1:.4f}

Key drivers from SHAP: {top_feature} and other high-importance features (see SHAP summary plot and table).
Business recommendations:
1) Target month-to-month and low-tenure customers with retention offers (discounts or incentives).
2) Offer bundled services to increase service_count (improves stickiness).
3) Monitor high value_score customers (high spend but few services) and consider personalized offers.

Limitations:
- No true monthly history per customer (we approximated monthly behavior with avg_monthly_spend).
- SHAP explains model behavior but causal experiments (A/B tests) are needed to validate interventions.
"""

print("\n--- EXECUTIVE SUMMARY (copy-paste) ---")
print(exec_summary)

# -------------------------
# 15) Save model & artifacts (optional)
# -------------------------
joblib.dump(best_model, "xgb_telco_churn_model.joblib")
feat_imp_df.to_csv("feature_importances.csv", index=False)
print("\nModel and feature importances saved to current folder.")

# End of notebook